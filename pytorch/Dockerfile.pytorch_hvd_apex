# export TAG="pytorch_hvd_apex"
# docker build -t nvcr.io/nvidian/sae/avolkov:$TAG -f Dockerfile.$TAG $(pwd)
# or two steps:
# docker build -t $TAG -f Dockerfile.$TAG $(pwd)
# docker tag $TAG nvcr.io/nvidian/sae/avolkov:$TAG
# docker push nvcr.io/nvidian/sae/avolkov:$TAG

FROM nvidia/cuda:9.0-devel-ubuntu16.04

# TensorFlow version is tightly coupled to CUDA and cuDNN so it should be selected carefully
# ENV TENSORFLOW_VERSION=1.10.0
ENV PYTORCH_VERSION=0.4.0
ENV CUDNN_VERSION=7.0.5.15-1+cuda9.0
ENV NCCL_VERSION=2.2.13-1+cuda9.0

# Python 2.7 or 3.5 is supported by Ubuntu Xenial out of the box
ARG python=3.5
ENV PYTHON_VERSION=${python}

RUN echo "deb http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /" \
    > /etc/apt/sources.list.d/nvidia-ml.list

# --allow-downgrades --allow-change-held-packages
RUN apt-get update && \
    apt-get install -y --no-install-recommends --allow-change-held-packages --allow-downgrades \
        build-essential \
        cmake \
        git \
        curl \
        vim \
        wget \
        ca-certificates \
        libcudnn7=${CUDNN_VERSION} \
        libnccl2=${NCCL_VERSION} \
        libnccl-dev=${NCCL_VERSION} \
        libjpeg-dev \
        libpng-dev \
        python${PYTHON_VERSION} \
        python${PYTHON_VERSION}-dev \
        pdsh

RUN ln -s /usr/bin/python${PYTHON_VERSION} /usr/bin/python

RUN curl -O https://bootstrap.pypa.io/get-pip.py && \
    python get-pip.py && \
    rm get-pip.py

# SETUP SSH -------------------------------------------------------------------

# Install OpenSSH for MPI to communicate between containers
RUN apt-get update && \
    apt-get install -y --no-install-recommends openssh-client openssh-server && \
    mkdir -p /var/run/sshd && \
    rm -rf /var/lib/apt/lists/*

# Allow OpenSSH to talk to containers without asking for confirmation
RUN cat /etc/ssh/ssh_config | grep -v StrictHostKeyChecking > /etc/ssh/ssh_config.new && \
    echo "    StrictHostKeyChecking no" >> /etc/ssh/ssh_config.new && \
    mv /etc/ssh/ssh_config.new /etc/ssh/ssh_config

# ref: https://docs.docker.com/engine/examples/running_ssh_service/#build-an-eg_sshd-image
RUN sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config

# SSH login fix. Otherwise user is kicked off after login
RUN sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd

# OS PACKAGES FOR RDMA, Infiniband, Hwloc -------------------------------------
RUN apt-get update && apt-get install -y \
        libhwloc-dev libnuma1 libnuma-dev && \
    rm -rf /var/lib/apt/lists/*


# Install Open MPI ------------------------------------------------------------
#     ./configure --enable-orterun-prefix-by-default --with-verbs 
# ./configure --enable-orterun-prefix-by-default --disable-getpwuid \
#     --prefix=/usr/local/openmpi --with-cuda --with-verbs && \
RUN mkdir /tmp/openmpi && \
    cd /tmp/openmpi && \
    wget https://download.open-mpi.org/release/open-mpi/v3.1/openmpi-3.1.2.tar.gz && \
    tar zxf openmpi-3.1.2.tar.gz && \
    cd openmpi-3.1.2 && \
    ./configure --enable-orterun-prefix-by-default && \
    make -j $(nproc) all && \
    make install && \
    ldconfig && \
    rm -rf /tmp/openmpi

# Create a wrapper for OpenMPI to allow running as root by default
RUN mv /usr/local/bin/mpirun /usr/local/bin/mpirun.real && \
    echo '#!/bin/bash' > /usr/local/bin/mpirun && \
    echo 'mpirun.real --allow-run-as-root "$@"' >> /usr/local/bin/mpirun && \
    chmod a+x /usr/local/bin/mpirun

# Configure OpenMPI to run good defaults:
#   --bind-to none --map-by slot --mca btl_tcp_if_exclude lo,docker0
RUN echo "hwloc_base_binding_policy = none" >> /usr/local/etc/openmpi-mca-params.conf && \
    echo "rmaps_base_mapping_policy = slot" >> /usr/local/etc/openmpi-mca-params.conf && \
    echo "btl_tcp_if_exclude = lo,docker0" >> /usr/local/etc/openmpi-mca-params.conf

# Set default NCCL parameters
RUN echo NCCL_DEBUG=INFO >> /etc/nccl.conf && \
    echo NCCL_SOCKET_IFNAME=^docker0 >> /etc/nccl.conf

# INSTALL TENSORFLOW AND KERAS ------------------------------------------------
# RUN pip install tensorflow-gpu==${TENSORFLOW_VERSION} keras h5py

# INSTALL PYTORCH -------------------------------------------------------------
RUN PY=$(echo ${PYTHON_VERSION} | sed s/\\.//); \
    if echo ${PYTHON_VERSION} | grep ^3 >/dev/null; then \
        pip install http://download.pytorch.org/whl/cu90/torch-${PYTORCH_VERSION}-cp${PY}-cp${PY}m-linux_x86_64.whl; \
    else \
        pip install http://download.pytorch.org/whl/cu90/torch-${PYTORCH_VERSION}-cp${PY}-cp${PY}mu-linux_x86_64.whl; \
    fi; \
    pip install torchvision

# INSTALL HOROVOD, temporarily using CUDA stubs -------------------------------
RUN ldconfig /usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs && \
    HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_WITH_PYTORCH=1 pip install --no-cache-dir horovod && \
    ldconfig

# INSTALL APEX ----------------------------------------------------------------
RUN pip install --no-cache-dir git+https://github.com/NVIDIA/apex.git#egg=apex


# OS PACKAGES FOR RDMA, Infiniband, Hwloc -------------------------------------
# libhwloc-dev libnuma1 libnuma-dev \
RUN apt-get update && apt-get install -y \
        librdmacm* \
        libibverbs-dev \
        libibverbs1 \
        librdmacm1 \
        librdmacm-dev \
        rdmacm-utils \
        libibmad-dev \
        libibmad5 \
        infiniband-diags \
        libmlx5-1 \
        libmlx4-1 && \
    rm -rf /var/lib/apt/lists/*


# EXAMPLES --------------------------------------------------------------------
# Download examples
RUN apt-get update && \
    apt-get install -y --no-install-recommends subversion && \
    svn checkout https://github.com/uber/horovod/trunk/examples && \
    rm -rf /examples/.svn && \
    rm -rf /var/lib/apt/lists/*

WORKDIR "/examples"
